{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SoumiNand/CI-CD-Project/blob/main/VFL_New_Hopefully_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b131b5a7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-29T10:31:47.986988Z",
          "iopub.status.busy": "2025-12-29T10:31:47.986563Z",
          "iopub.status.idle": "2025-12-29T10:32:50.317552Z",
          "shell.execute_reply": "2025-12-29T10:32:50.316701Z"
        },
        "id": "b131b5a7",
        "papermill": {
          "duration": 62.340612,
          "end_time": "2025-12-29T10:32:50.319368",
          "exception": false,
          "start_time": "2025-12-29T10:31:47.978756",
          "status": "completed"
        },
        "tags": [],
        "outputId": "2a6be1a7-2d9d-45ce-c2a6-ec0eb5450253"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
            "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
            "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
            "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# install\n",
        "!pip install torch torchvision tqdm scikit-learn pandas numpy matplotlib --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efeb4e98",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-29T10:32:50.363473Z",
          "iopub.status.busy": "2025-12-29T10:32:50.363189Z",
          "iopub.status.idle": "2025-12-29T10:33:35.272386Z",
          "shell.execute_reply": "2025-12-29T10:33:35.271330Z"
        },
        "id": "efeb4e98",
        "papermill": {
          "duration": 44.932576,
          "end_time": "2025-12-29T10:33:35.273893",
          "exception": false,
          "start_time": "2025-12-29T10:32:50.341317",
          "status": "completed"
        },
        "tags": [],
        "outputId": "36a5730f-ccb2-40e7-f668-c979f928a152"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-29 10:33:13.828941: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1767004394.036176      12 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1767004394.091693      12 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import timm\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bc34a2a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "execution": {
          "iopub.execute_input": "2025-12-29T10:33:35.320208Z",
          "iopub.status.busy": "2025-12-29T10:33:35.319602Z",
          "iopub.status.idle": "2025-12-29T10:33:35.566785Z",
          "shell.execute_reply": "2025-12-29T10:33:35.565791Z"
        },
        "id": "3bc34a2a",
        "outputId": "fbb2bac5-a849-4ba7-a237-3b8b26abca1b",
        "papermill": {
          "duration": 0.271709,
          "end_time": "2025-12-29T10:33:35.568214",
          "exception": true,
          "start_time": "2025-12-29T10:33:35.296505",
          "status": "failed"
        },
        "tags": []
      },
      "outputs": [
        {
          "ename": "NotImplementedError",
          "evalue": "Mounting drive is unsupported in this environment. Use PyDrive2 instead. See examples at https://colab.research.google.com/notebooks/io.ipynb#scrollTo=7taylj9wpsA2.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_12/1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    116\u001b[0m   \u001b[0;34m\"\"\"Internal helper to mount Google Drive.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/var/colab/hostname'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     raise NotImplementedError(\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;34m'Mounting drive is unsupported in this environment. Use PyDrive2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;34m' instead. See examples at'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: Mounting drive is unsupported in this environment. Use PyDrive2 instead. See examples at https://colab.research.google.com/notebooks/io.ipynb#scrollTo=7taylj9wpsA2."
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8531f27",
      "metadata": {
        "id": "c8531f27",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b07e778",
      "metadata": {
        "id": "9b07e778",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "913b6e4c",
      "metadata": {
        "id": "913b6e4c",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(\"Loading datasets...\")\n",
        "df_ratings = pd.read_csv('/content/drive/MyDrive/ratings.csv')\n",
        "df_movies = pd.read_csv('/content/drive/MyDrive/movies.csv')\n",
        "df_credits = pd.read_csv('/content/drive/MyDrive/credits.csv')\n",
        "df_tags = pd.read_csv('/content/drive/MyDrive/tags.csv')\n",
        "df_genome_scores = pd.read_csv('/content/drive/MyDrive/genome-scores.csv')\n",
        "df_genome_tags = pd.read_csv('/content/drive/MyDrive/genome-tags.csv')\n",
        "\n",
        "# Drop timestamp from ratings\n",
        "if 'timestamp' in df_ratings.columns:\n",
        "    df_ratings = df_ratings.drop('timestamp', axis=1)\n",
        "\n",
        "# Merge genome data\n",
        "print(\"Merging genome data...\")\n",
        "df_genomes = pd.merge(df_genome_scores, df_genome_tags, on='tagId', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f09b56b",
      "metadata": {
        "id": "2f09b56b",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "df_ratings.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb2cfb09",
      "metadata": {
        "id": "eb2cfb09",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "df_movies.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2de67185",
      "metadata": {
        "id": "2de67185",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "df_credits.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfff5246",
      "metadata": {
        "id": "bfff5246",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "df_genomes.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d7503c8",
      "metadata": {
        "id": "0d7503c8",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "df_genome_scores.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00352173",
      "metadata": {
        "id": "00352173",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "df_genome_tags.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96ef3455",
      "metadata": {
        "id": "96ef3455",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "df_tags.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef9d28d3",
      "metadata": {
        "id": "ef9d28d3",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(\"Finding common movies across all datasets...\")\n",
        "common_movies = set(df_ratings['movieId'].unique())\n",
        "common_movies = common_movies.intersection(set(df_movies['movieId'].unique()))\n",
        "common_movies = common_movies.intersection(set(df_credits['id'].unique()))\n",
        "common_movies = common_movies.intersection(set(df_genomes['movieId'].unique()))\n",
        "common_movies = common_movies.intersection(set(df_tags['movieId'].unique()))\n",
        "common_movies = sorted(list(common_movies))\n",
        "\n",
        "print(f\"Number of common movies across all datasets: {len(common_movies)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26a301b0",
      "metadata": {
        "id": "26a301b0",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "df_ratings = df_ratings[df_ratings['movieId'].isin(common_movies)].reset_index(drop=True)\n",
        "df_movies = df_movies[df_movies['movieId'].isin(common_movies)].reset_index(drop=True)\n",
        "df_credits = df_credits[df_credits['id'].isin(common_movies)].reset_index(drop=True)\n",
        "df_genomes = df_genomes[df_genomes['movieId'].isin(common_movies)].reset_index(drop=True)\n",
        "df_tags = df_tags[df_tags['movieId'].isin(common_movies)].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6848b02a",
      "metadata": {
        "id": "6848b02a",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(\"Encoding users and movies...\")\n",
        "user_encoder = LabelEncoder()\n",
        "movie_encoder = LabelEncoder()\n",
        "\n",
        "df_ratings['user_idx'] = user_encoder.fit_transform(df_ratings['userId'])\n",
        "df_ratings['movie_idx'] = movie_encoder.fit_transform(df_ratings['movieId'])\n",
        "\n",
        "num_users = df_ratings['user_idx'].nunique()\n",
        "num_movies = df_ratings['movie_idx'].nunique()\n",
        "\n",
        "print(f\"\\nDataset Statistics:\")\n",
        "print(f\"  Number of users: {num_users}\")\n",
        "print(f\"  Number of movies: {num_movies}\")\n",
        "print(f\"  Number of ratings: {len(df_ratings)}\")\n",
        "print(f\"  Rating range: {df_ratings['rating'].min()} to {df_ratings['rating'].max()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6982d2b3",
      "metadata": {
        "id": "6982d2b3",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# =====================================\n",
        "# FIXED Aligned VFL Dataset for Opacus\n",
        "# =====================================\n",
        "class AlignedVFLDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.data = df.reset_index(drop=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "\n",
        "        user_idx  = torch.tensor(row[\"user_idx\"], dtype=torch.long)\n",
        "        movie_idx = torch.tensor(row[\"movie_idx\"], dtype=torch.long)\n",
        "        movieId   = torch.tensor(row[\"movieId\"], dtype=torch.long)\n",
        "        rating    = torch.tensor(row[\"rating\"], dtype=torch.float32)\n",
        "\n",
        "        # Combine 3 features into a single vector (Opacus-friendly)\n",
        "        X = torch.stack([user_idx, movie_idx, movieId])  # [3]\n",
        "        y = rating\n",
        "\n",
        "        return X, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5b195c6",
      "metadata": {
        "id": "b5b195c6",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(\"\\nCreating train/test split...\")\n",
        "train_df, test_df = train_test_split(df_ratings, test_size=0.2, random_state=42)\n",
        "\n",
        "# Take only first 500 samples from training data\n",
        "train_df = train_df.head(500).reset_index(drop=True)\n",
        "\n",
        "# For test set, take proportionally fewer (e.g., 100 samples)\n",
        "test_df = test_df.head(100).reset_index(drop=True)\n",
        "\n",
        "train_dataset = AlignedVFLDataset(train_df)\n",
        "test_dataset = AlignedVFLDataset(test_df)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=8,\n",
        "    shuffle=True,\n",
        "    num_workers=0,   # ğŸ‘ˆ set to 0 temporarily\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=8,\n",
        "    shuffle=False,\n",
        "    num_workers=0,   # ğŸ‘ˆ 0 here as well\n",
        ")\n",
        "\n",
        "\n",
        "print(f\"Train samples: {len(train_dataset)}\")\n",
        "print(f\"Test samples: {len(test_dataset)}\")\n",
        "print(f\"Batch size: 8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c316fca6",
      "metadata": {
        "id": "c316fca6",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# ============ CLIENT A: MOVIES MODEL ============\n",
        "class MoviesBottomModel(nn.Module):\n",
        "    def __init__(self, num_movies, num_genres, embedding_dim=64):\n",
        "        super().__init__()\n",
        "        self.movie_to_genres = {}\n",
        "        self.num_genres = num_genres\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        # Encoder: genres â†’ embedding\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(num_genres, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, embedding_dim)\n",
        "        )\n",
        "\n",
        "    def setup_genres_mapping(self, df_movies):\n",
        "        \"\"\"Create mapping from movieId to genre vector\"\"\"\n",
        "        df_movies = df_movies.copy()\n",
        "        df_movies['genres_list'] = df_movies['genres'].apply(\n",
        "            lambda x: [] if x == \"(no genres listed)\" else x.split(\"|\")\n",
        "        )\n",
        "\n",
        "        mlb = MultiLabelBinarizer()\n",
        "        genres_matrix = mlb.fit_transform(df_movies['genres_list'])\n",
        "\n",
        "        for idx, row in df_movies.iterrows():\n",
        "            movie_id = row['movieId']\n",
        "            self.movie_to_genres[movie_id] = genres_matrix[idx]\n",
        "\n",
        "        print(f\"Movies client: Loaded {len(self.movie_to_genres)} movies with {self.num_genres} genres\")\n",
        "\n",
        "    def forward(self, movieIds):\n",
        "        if movieIds.numel() == 0:\n",
        "          return torch.zeros((0, self.embedding_dim), device=movieIds.device)\n",
        "        batch_size = movieIds.size(0)\n",
        "        genre_vectors = torch.zeros(batch_size, self.num_genres, device=movieIds.device)\n",
        "\n",
        "        for i, movie_id in enumerate(movieIds.cpu().numpy()):\n",
        "            if movie_id in self.movie_to_genres:\n",
        "                genre_vectors[i] = torch.tensor(self.movie_to_genres[movie_id], dtype=torch.float32)\n",
        "\n",
        "        embedding = self.encoder(genre_vectors)\n",
        "        return embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6345c795",
      "metadata": {
        "id": "6345c795",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# ============ CLIENT B: CREDITS MODEL ============\n",
        "class CreditsBottomModel(nn.Module):\n",
        "    def __init__(self, num_movies, embedding_dim=128):\n",
        "        super().__init__()\n",
        "        self.movie_to_credits = {}\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.feature_dim = None\n",
        "        self.encoder = None\n",
        "\n",
        "    def setup_credits_mapping(self, df_credits):\n",
        "        \"\"\"Preprocess credits data and create embeddings\"\"\"\n",
        "        df_credits = df_credits.copy()\n",
        "\n",
        "        def extract_names(cast_json, limit=5):\n",
        "            try:\n",
        "                cast_list = json.loads(cast_json.replace(\"'\", '\"'))\n",
        "                return [person.get('name', '') for person in cast_list[:limit]]\n",
        "            except:\n",
        "                return []\n",
        "\n",
        "        # Extract top cast names\n",
        "        df_credits['cast_names'] = df_credits['cast'].apply(lambda x: extract_names(x, 5))\n",
        "        df_credits['cast_text'] = df_credits['cast_names'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "        # TF-IDF vectorization\n",
        "        vectorizer = TfidfVectorizer(max_features=200, stop_words='english')\n",
        "        credits_features = vectorizer.fit_transform(df_credits['cast_text']).toarray()\n",
        "\n",
        "        self.feature_dim = credits_features.shape[1]\n",
        "\n",
        "        # Initialize encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, self.embedding_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Store features\n",
        "        for idx, row in df_credits.iterrows():\n",
        "            movie_id = row['id']\n",
        "            self.movie_to_credits[movie_id] = credits_features[idx]\n",
        "\n",
        "        print(f\"Credits client: Loaded {len(self.movie_to_credits)} movies with {self.feature_dim} features\")\n",
        "\n",
        "    def forward(self, movieIds):\n",
        "        if self.encoder is None:\n",
        "            raise RuntimeError(\"Must call setup_credits_mapping first!\")\n",
        "\n",
        "        batch_size = movieIds.size(0)\n",
        "        credit_vectors = torch.zeros(batch_size, self.feature_dim, device=movieIds.device)\n",
        "\n",
        "        for i, movie_id in enumerate(movieIds.cpu().numpy()):\n",
        "            if movie_id in self.movie_to_credits:\n",
        "                credit_vectors[i] = torch.tensor(self.movie_to_credits[movie_id], dtype=torch.float32)\n",
        "\n",
        "        embedding = self.encoder(credit_vectors)\n",
        "        return embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efe922d4",
      "metadata": {
        "id": "efe922d4",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "!pip install open_clip_torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e2b034e",
      "metadata": {
        "id": "9e2b034e",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class LoRALinear(nn.Module):\n",
        "    def __init__(self, base_layer, r=4, alpha=8):\n",
        "        super().__init__()\n",
        "        self.base = base_layer\n",
        "        self.r = r\n",
        "        self.lora_A = nn.Linear(base_layer.in_features, r, bias=False)\n",
        "        self.lora_B = nn.Linear(r, base_layer.out_features, bias=False)\n",
        "        self.scaling = alpha / r\n",
        "\n",
        "        # init LoRA parameters small, freeze base\n",
        "        nn.init.kaiming_uniform_(self.lora_A.weight, a=math.sqrt(5))\n",
        "        nn.init.zeros_(self.lora_B.weight)\n",
        "        for p in self.base.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base(x) + self.scaling * self.lora_B(self.lora_A(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c86234c1",
      "metadata": {
        "id": "c86234c1",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import open_clip\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# ============ CLIENT C: TAGS + POSTERS MODEL (Multimodal via CLIP) ============\n",
        "class TagsPosterBottomModel(nn.Module):\n",
        "    def __init__(self, num_movies, embedding_dim=512, device=\"cpu\"):\n",
        "        super().__init__()\n",
        "        self.movie_to_tags_text = {}   # raw combined tag text per movie\n",
        "        self.movie_to_poster = {}\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.device = torch.device(device)\n",
        "\n",
        "        # --- Load CLIP (open_clip) ---\n",
        "        self.clip_model, self.clip_train_preprocess, self.clip_eval_preprocess = \\\n",
        "            open_clip.create_model_and_transforms(\n",
        "                \"ViT-B-32\", pretrained=\"laion2b_e16\"\n",
        "            )\n",
        "        self.clip_tokenizer = open_clip.get_tokenizer(\"ViT-B-32\")\n",
        "        self.clip_model = self.clip_model.to(self.device)\n",
        "        self.clip_model.eval()  # keep backbone frozen\n",
        "\n",
        "        # Dim of CLIP embeddings (image & text share this)\n",
        "        self.clip_embed_dim = self.clip_model.text_projection.shape[1]\n",
        "\n",
        "        # Fusion MLP over [img_emb ; txt_emb] -> embedding_dim\n",
        "        self.fusion_mlp = nn.Sequential(\n",
        "            nn.Linear(self.clip_embed_dim * 2, embedding_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(embedding_dim, embedding_dim),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.has_posters = False\n",
        "\n",
        "    def setup_tags_posters_mapping(self, df_tags, posters_dir=None):\n",
        "        \"\"\"Preprocess tags and posters data: store raw tag text + poster paths.\"\"\"\n",
        "        df_tags = df_tags.copy()\n",
        "        print(\"Setting up Tags + Posters client (CLIP-based)...\")\n",
        "\n",
        "        # Combine tags to a single string per movie\n",
        "        df_tags[\"tag\"] = df_tags[\"tag\"].astype(str)\n",
        "        movie_tags = df_tags.groupby(\"movieId\")[\"tag\"].apply(\n",
        "            lambda x: \" \".join(x)\n",
        "        ).reset_index()\n",
        "\n",
        "        # Posters\n",
        "        poster_map = {}\n",
        "        if posters_dir is not None and os.path.exists(posters_dir):\n",
        "            self.has_posters = True\n",
        "            for f in os.listdir(posters_dir):\n",
        "                try:\n",
        "                    mid = int(f.split(\".\")[0])\n",
        "                    poster_map[mid] = os.path.join(posters_dir, f)\n",
        "                except Exception:\n",
        "                    continue\n",
        "            print(f\"Found {len(poster_map)} poster images\")\n",
        "        else:\n",
        "            print(\"Warning: No posters directory. Using tags only.\")\n",
        "            self.has_posters = False\n",
        "\n",
        "        # If we have posters, restrict to movies with both tags and posters\n",
        "        if self.has_posters:\n",
        "            movie_tags_filtered = movie_tags[movie_tags[\"movieId\"].isin(poster_map.keys())].reset_index(drop=True)\n",
        "            print(f\"Movies with both tags and posters: {len(movie_tags_filtered)}\")\n",
        "\n",
        "            for _, row in movie_tags_filtered.iterrows():\n",
        "                mid = int(row[\"movieId\"])\n",
        "                self.movie_to_tags_text[mid] = row[\"tag\"]\n",
        "                self.movie_to_poster[mid] = poster_map[mid]\n",
        "        else:\n",
        "            for _, row in movie_tags.iterrows():\n",
        "                mid = int(row[\"movieId\"])\n",
        "                self.movie_to_tags_text[mid] = row[\"tag\"]\n",
        "\n",
        "        print(f\"Tags+Posters client (CLIP): Loaded {len(self.movie_to_tags_text)} movies\")\n",
        "\n",
        "    def _load_and_process_image(self, poster_path):\n",
        "        \"\"\"Use CLIP's own preprocess pipeline for images, with safe fallback.\"\"\"\n",
        "        try:\n",
        "            if not poster_path or not os.path.exists(poster_path):\n",
        "                raise FileNotFoundError\n",
        "            img = Image.open(poster_path).convert(\"RGB\")\n",
        "            img_tensor = self.clip_eval_preprocess(img)  # open_clip transform\n",
        "            return img_tensor\n",
        "        except Exception:\n",
        "            # Fallback: CLIP expects 3x224x224-like tensor, use zeros\n",
        "            return torch.zeros(3, 224, 224)\n",
        "\n",
        "    def forward(self, movieIds):\n",
        "        \"\"\"\n",
        "        movieIds: LongTensor [B]\n",
        "        Returns: fused embedding [B, embedding_dim]\n",
        "        \"\"\"\n",
        "        if movieIds is None or movieIds.numel() == 0:\n",
        "            return torch.zeros((0, self.embedding_dim), device=self.device)\n",
        "        batch_size = movieIds.size(0)\n",
        "        device = movieIds.device\n",
        "\n",
        "        # Ensure CLIP model is on the correct device\n",
        "        if next(self.clip_model.parameters()).device != device:\n",
        "            self.clip_model = self.clip_model.to(device)\n",
        "\n",
        "        images = []\n",
        "        tag_texts = []\n",
        "\n",
        "        # Build per-movie text and image\n",
        "        for mid in movieIds.cpu().numpy():\n",
        "            mid = int(mid)\n",
        "\n",
        "            # Text: tags string\n",
        "            if mid in self.movie_to_tags_text:\n",
        "                tag_texts.append(self.movie_to_tags_text[mid])\n",
        "            else:\n",
        "                tag_texts.append(\"\")\n",
        "\n",
        "            # Image: poster or zero-image\n",
        "            if self.has_posters and mid in self.movie_to_poster:\n",
        "                img_tensor = self._load_and_process_image(self.movie_to_poster[mid])\n",
        "            else:\n",
        "                img_tensor = torch.zeros(3, 224, 224)\n",
        "            images.append(img_tensor)\n",
        "\n",
        "        # Always non-empty because we append one image per movieId\n",
        "        image_batch = torch.stack(images).to(device)          # [B, 3, 224, 224]\n",
        "        text_tokens = self.clip_tokenizer(tag_texts).to(device)\n",
        "\n",
        "        with torch.no_grad():  # CLIP backbone frozen\n",
        "            img_emb = self.clip_model.encode_image(image_batch)   # [B, d]\n",
        "            txt_emb = self.clip_model.encode_text(text_tokens)    # [B, d]\n",
        "\n",
        "        # Normalize (standard CLIP practice)\n",
        "        img_emb = img_emb / img_emb.norm(dim=-1, keepdim=True)\n",
        "        txt_emb = txt_emb / txt_emb.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        # Fuse: concat + small MLP to embedding_dim\n",
        "        fused_input = torch.cat([img_emb, txt_emb], dim=1)  # [B, 2d]\n",
        "        embedding = self.fusion_mlp(fused_input)            # [B, embedding_dim]\n",
        "\n",
        "        return embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7659562c",
      "metadata": {
        "id": "7659562c",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class GenomesBottomModel(nn.Module):\n",
        "    def __init__(self, num_movies, num_tags, embedding_dim=64):\n",
        "        super().__init__()\n",
        "        self.movie_to_genome = {}\n",
        "        self.num_tags = num_tags\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(num_tags, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, embedding_dim)\n",
        "        )\n",
        "\n",
        "    def setup_genomes_mapping(self, df_genomes):\n",
        "        \"\"\"Create genome relevance vectors\"\"\"\n",
        "        genome_pivot = df_genomes.pivot_table(\n",
        "            index='movieId',\n",
        "            columns='tagId',\n",
        "            values='relevance',\n",
        "            fill_value=0\n",
        "        )\n",
        "\n",
        "        for movie_id in genome_pivot.index:\n",
        "            self.movie_to_genome[movie_id] = genome_pivot.loc[movie_id].values\n",
        "\n",
        "        print(f\"Genomes client: Loaded {len(self.movie_to_genome)} movies with {self.num_tags} genome tags\")\n",
        "\n",
        "    def forward(self, movieIds):\n",
        "        batch_size = movieIds.size(0)\n",
        "        genome_vectors = torch.zeros(batch_size, self.num_tags, device=movieIds.device)\n",
        "\n",
        "        for i, movie_id in enumerate(movieIds.cpu().numpy()):\n",
        "            if movie_id in self.movie_to_genome:\n",
        "                genome_vectors[i] = torch.tensor(self.movie_to_genome[movie_id], dtype=torch.float32)\n",
        "\n",
        "        embedding = self.encoder(genome_vectors)\n",
        "        return embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d61e973",
      "metadata": {
        "id": "7d61e973",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class TopAggregatorModel(nn.Module):\n",
        "    def __init__(self, num_users, total_embedding_dim, hidden_layers=[256, 128, 64]):\n",
        "        super().__init__()\n",
        "\n",
        "        # User embedding\n",
        "        self.user_embedding = nn.Embedding(num_users, 50)\n",
        "\n",
        "        # MLP layers\n",
        "        layers = []\n",
        "        input_dim = 50 + total_embedding_dim\n",
        "        for hidden_dim in hidden_layers:\n",
        "          layers.extend([\n",
        "                  nn.Linear(input_dim, hidden_dim),\n",
        "                  nn.ReLU(),\n",
        "                  nn.GroupNorm(1, hidden_dim),  # 1 group = LayerNorm-like, DP-safe\n",
        "                  nn.Dropout(0.3),\n",
        "              ])\n",
        "          input_dim = hidden_dim\n",
        "        layers.append(nn.Linear(input_dim, 1))\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "    def forward(self, user_idx, combined_embeddings):\n",
        "        user_emb = self.user_embedding(user_idx)\n",
        "        fusion_input = torch.cat([user_emb, combined_embeddings], dim=1)\n",
        "        output = self.mlp(fusion_input)\n",
        "        return output.squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8520d9e9",
      "metadata": {
        "id": "8520d9e9",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class BottomClient:\n",
        "    def __init__(self, name, model, device):\n",
        "        self.name = name\n",
        "        self.model = model.to(device)\n",
        "        self.device = device\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
        "        self.current_embeddings = None\n",
        "\n",
        "    def forward(self, movieIds):\n",
        "        \"\"\"Forward pass through bottom model\"\"\"\n",
        "        self.model.train()\n",
        "        movieIds = movieIds.to(self.device)\n",
        "        embeddings = self.model(movieIds)\n",
        "        self.current_embeddings = embeddings\n",
        "        return embeddings\n",
        "\n",
        "    def backward(self, gradients):\n",
        "        \"\"\"Backward pass through bottom model\"\"\"\n",
        "        if self.current_embeddings is None:\n",
        "            raise RuntimeError(\"Must call forward() before backward()\")\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        self.current_embeddings.backward(gradients)\n",
        "        self.optimizer.step()\n",
        "\n",
        "    def eval_mode(self):\n",
        "        self.model.eval()\n",
        "\n",
        "    def train_mode(self):\n",
        "        self.model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afc5695d",
      "metadata": {
        "id": "afc5695d",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "!pip install opacus\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2463afe0",
      "metadata": {
        "id": "2463afe0",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "from opacus import PrivacyEngine\n",
        "\n",
        "class VFLCoordinator:\n",
        "    def __init__(self, bottom_clients, top_model, device):\n",
        "        self.clients = bottom_clients\n",
        "        self.top_model = top_model.to(device)\n",
        "        self.device = device\n",
        "\n",
        "        # Top model optimizer\n",
        "        self.optimizer_top = optim.Adam(self.top_model.parameters(), lr=0.001)\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "        # Will be set later with make_private()\n",
        "        self.privacy_engine = None\n",
        "\n",
        "    def make_private(self, train_loader, target_epsilon, target_delta, epochs, max_grad_norm=1.0):\n",
        "      \"\"\"\n",
        "      Make top_model DP with epsilon-targeted training.\n",
        "\n",
        "      target_epsilon: desired total Îµ after `epochs` epochs\n",
        "      target_delta:   e.g. 1e-5\n",
        "      epochs:         how many epochs you plan to train\n",
        "      \"\"\"\n",
        "      self.privacy_engine = PrivacyEngine()\n",
        "      self.top_model, self.optimizer_top, self.dp_train_loader = \\\n",
        "          self.privacy_engine.make_private_with_epsilon(\n",
        "              module=self.top_model,\n",
        "              optimizer=self.optimizer_top,\n",
        "              data_loader=train_loader,\n",
        "              target_epsilon=target_epsilon,\n",
        "              target_delta=target_delta,\n",
        "              epochs=epochs,\n",
        "              max_grad_norm=max_grad_norm,\n",
        "          )\n",
        "\n",
        "\n",
        "    def forward_pass(self, movieIds, user_idx):\n",
        "        \"\"\"Collect embeddings from all clients and forward through top model\"\"\"\n",
        "        embeddings_dict = {}\n",
        "        embeddings_list = []\n",
        "\n",
        "        for name, client in self.clients.items():\n",
        "            emb = client.forward(movieIds)\n",
        "            embeddings_dict[name] = emb\n",
        "            embeddings_list.append(emb)\n",
        "\n",
        "        combined_embeddings = torch.cat(embeddings_list, dim=1)\n",
        "        combined_embeddings.retain_grad()\n",
        "        predictions = self.top_model(user_idx, combined_embeddings)\n",
        "        return predictions, embeddings_dict, combined_embeddings\n",
        "\n",
        "    def backward_pass(self, loss, embeddings_dict, combined_embeddings):\n",
        "        \"\"\"Compute gradients and send back to clients\"\"\"\n",
        "        self.optimizer_top.zero_grad()\n",
        "        loss.backward(retain_graph=True)\n",
        "        self.optimizer_top.step()\n",
        "\n",
        "        # Split gradients for each client\n",
        "        start_idx = 0\n",
        "        for name, client in self.clients.items():\n",
        "            emb = embeddings_dict[name]\n",
        "            end_idx = start_idx + emb.size(1)\n",
        "\n",
        "            grad_slice = combined_embeddings.grad[:, start_idx:end_idx]\n",
        "            client.backward(grad_slice)\n",
        "\n",
        "            start_idx = end_idx\n",
        "\n",
        "    def train_epoch(self, data_loader):\n",
        "      self.top_model.train()\n",
        "      for client in self.clients.values():\n",
        "          client.train_mode()\n",
        "\n",
        "      total_loss = 0.0\n",
        "      num_batches = 0\n",
        "\n",
        "      for X, y in tqdm(data_loader, desc=\"Training\"):\n",
        "        X = X.to(self.device)\n",
        "        y = y.to(self.device)\n",
        "\n",
        "        user_idx = X[:, 0].long()\n",
        "        movieIds = X[:, 1].long()\n",
        "        ratings = y.float()\n",
        "\n",
        "\n",
        "        predictions, embeddings_dict, combined_embeddings = self.forward_pass(\n",
        "              movieIds, user_idx\n",
        "          )\n",
        "        loss = self.criterion(predictions, ratings)\n",
        "        self.backward_pass(loss, embeddings_dict, combined_embeddings)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "      # Optional: report epsilon after each epoch (only if privacy_engine exists)\n",
        "      if getattr(self, \"privacy_engine\", None) is not None:\n",
        "          # New Opacus API\n",
        "          epsilon = self.privacy_engine.get_epsilon(delta=1e-5)\n",
        "          print(f\"(DP) Îµ = {epsilon:.2f}, Î´ = 1e-5\")\n",
        "\n",
        "      return total_loss / num_batches\n",
        "\n",
        "\n",
        "    def evaluate(self, data_loader):\n",
        "        \"\"\"Evaluate on test set (no noise)\"\"\"\n",
        "        self.top_model.eval()\n",
        "        for client in self.clients.values():\n",
        "            client.eval_mode()\n",
        "\n",
        "        total_loss = 0.0\n",
        "        num_batches = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "          for X, y in tqdm(data_loader, desc=\"Evaluating\"):\n",
        "            X = X.to(self.device)      # [B, 3]\n",
        "            y = y.to(self.device)\n",
        "            if X.numel() == 0:\n",
        "              continue\n",
        "\n",
        "            user_idx = X[:, 0].long()\n",
        "            movieIds = X[:, 1].long()\n",
        "            ratings  = y.float()\n",
        "\n",
        "            # collect embeddings from all clients\n",
        "            embeddings_list = []\n",
        "            for client in self.clients.values():\n",
        "                emb = client.model(movieIds.to(self.device))\n",
        "                embeddings_list.append(emb)\n",
        "\n",
        "            combined_embeddings = torch.cat(embeddings_list, dim=1)\n",
        "            predictions = self.top_model(user_idx, combined_embeddings)\n",
        "\n",
        "            loss = self.criterion(predictions, ratings)\n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "\n",
        "        return total_loss / num_batches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06784391",
      "metadata": {
        "id": "06784391",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"INITIALIZING VERTICAL FEDERATED LEARNING MODELS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Determine dimensions\n",
        "df_movies_temp = df_movies.copy()\n",
        "df_movies_temp['genres_list'] = df_movies_temp['genres'].apply(\n",
        "    lambda x: [] if x == \"(no genres listed)\" else x.split(\"|\")\n",
        ")\n",
        "mlb = MultiLabelBinarizer()\n",
        "mlb.fit(df_movies_temp['genres_list'])\n",
        "num_genres = len(mlb.classes_)\n",
        "\n",
        "num_genome_tags = df_genomes['tagId'].nunique()\n",
        "\n",
        "print(f\"\\nDimension Information:\")\n",
        "print(f\"  Number of genres: {num_genres}\")\n",
        "print(f\"  Number of genome tags: {num_genome_tags}\")\n",
        "\n",
        "# Initialize bottom models\n",
        "print(\"\\n\" + \"-\"*60)\n",
        "print(\"Initializing Bottom Client Models\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "print(\"\\n[1/4] Initializing Movies Client...\")\n",
        "client_movies = MoviesBottomModel(num_movies, num_genres, embedding_dim=64)\n",
        "client_movies.setup_genres_mapping(df_movies)\n",
        "\n",
        "print(\"\\n[2/4] Initializing Credits Client...\")\n",
        "client_credits = CreditsBottomModel(num_movies, embedding_dim=128)\n",
        "client_credits.setup_credits_mapping(df_credits)\n",
        "\n",
        "print(\"\\n[3/4] Initializing Tags+Posters Client...\")\n",
        "# Set your posters directory path here\n",
        "posters_directory = \"/content/drive/MyDrive/ml-20m-psm/posters\"  # Change this to your path\n",
        "\n",
        "client_tags_posters = TagsPosterBottomModel(num_movies, embedding_dim=512)\n",
        "if os.path.exists(posters_directory):\n",
        "    print(f\"Found posters directory: {posters_directory}\")\n",
        "    client_tags_posters.setup_tags_posters_mapping(df_tags, posters_directory)\n",
        "else:\n",
        "    print(f\"Posters directory not found. Using tags only.\")\n",
        "    client_tags_posters.setup_tags_posters_mapping(df_tags, None)\n",
        "\n",
        "print(\"\\n[4/4] Initializing Genomes Client...\")\n",
        "client_genomes = GenomesBottomModel(num_movies, num_genome_tags, embedding_dim=64)\n",
        "client_genomes.setup_genomes_mapping(df_genomes)\n",
        "\n",
        "# Wrap in BottomClient class\n",
        "print(\"\\n\" + \"-\"*60)\n",
        "print(\"Creating Client Wrappers\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "clients_dict = {\n",
        "    'movies': BottomClient('movies', client_movies, device),\n",
        "    'credits': BottomClient('credits', client_credits, device),\n",
        "    'tags_posters': BottomClient('tags_posters', client_tags_posters, device),\n",
        "    'genomes': BottomClient('genomes', client_genomes, device)\n",
        "}\n",
        "\n",
        "# Calculate total embedding dimension\n",
        "total_embedding_dim = 64 + 128 + 512 + 64  # 768\n",
        "\n",
        "print(f\"\\nEmbedding Dimensions:\")\n",
        "print(f\"  Movies:        64\")\n",
        "print(f\"  Credits:      128\")\n",
        "print(f\"  Tags+Posters: 512\")\n",
        "print(f\"  Genomes:       64\")\n",
        "print(f\"  {'â”€'*25}\")\n",
        "print(f\"  Total:        {total_embedding_dim}\")\n",
        "\n",
        "# Initialize top model\n",
        "print(\"\\n\" + \"-\"*60)\n",
        "print(\"Initializing Top Aggregator Model\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "top_model = TopAggregatorModel(\n",
        "    num_users=num_users,\n",
        "    total_embedding_dim=total_embedding_dim,\n",
        "    hidden_layers=[256, 128, 64]\n",
        ")\n",
        "\n",
        "total_params = sum(p.numel() for p in top_model.parameters())\n",
        "trainable_params = sum(p.numel() for p in top_model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"Top model parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODEL INITIALIZATION COMPLETE\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a21ff7a9",
      "metadata": {
        "collapsed": true,
        "id": "a21ff7a9",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1) Build clients ONCE\n",
        "client_movies = MoviesBottomModel(num_movies, num_genres, embedding_dim=64)\n",
        "client_movies.setup_genres_mapping(df_movies)\n",
        "\n",
        "client_credits = CreditsBottomModel(num_movies, embedding_dim=128)\n",
        "client_credits.setup_credits_mapping(df_credits)\n",
        "\n",
        "client_tags_posters = TagsPosterBottomModel(num_movies, embedding_dim=512, device=device)\n",
        "if os.path.exists(posters_directory):\n",
        "    client_tags_posters.setup_tags_posters_mapping(df_tags, posters_directory)\n",
        "else:\n",
        "    client_tags_posters.setup_tags_posters_mapping(df_tags, None)\n",
        "\n",
        "client_genomes = GenomesBottomModel(num_movies, num_genome_tags, embedding_dim=64)\n",
        "client_genomes.setup_genomes_mapping(df_genomes)\n",
        "\n",
        "clients_dict = {\n",
        "    'movies': BottomClient('movies', client_movies, device),\n",
        "    'credits': BottomClient('credits', client_credits, device),\n",
        "    'tags_posters': BottomClient('tags_posters', client_tags_posters, device),\n",
        "    'genomes': BottomClient('genomes', client_genomes, device),\n",
        "}\n",
        "\n",
        "# 2) Sweep epsilon targets\n",
        "epsilon_targets = np.linspace(1.0, 2.0, num=10)  # 1.0,1.11,...,2.0\n",
        "TARGET_DELTA = 1e-5\n",
        "num_epochs = 20\n",
        "all_results = []\n",
        "\n",
        "for TARGET_EPSILON in epsilon_targets:\n",
        "    print(f\"\\n=== Running with target Îµ = {TARGET_EPSILON:.2f} ===\")\n",
        "\n",
        "    # New top model and coordinator for this Îµ\n",
        "    total_embedding_dim = 64 + 128 + 512 + 64\n",
        "    top_model = TopAggregatorModel(\n",
        "        num_users=num_users,\n",
        "        total_embedding_dim=total_embedding_dim,\n",
        "        hidden_layers=[256, 128, 64],\n",
        "    )\n",
        "\n",
        "    print(\"\\nCreating VFL Coordinator...\")\n",
        "    coordinator = VFLCoordinator(\n",
        "        bottom_clients=clients_dict,\n",
        "        top_model=top_model,\n",
        "        device=device,\n",
        "    )\n",
        "    coordinator.top_model.train()\n",
        "\n",
        "    # Make the top model DP with epsilon-targeted Opacus\n",
        "    coordinator.make_private(\n",
        "        train_loader=train_loader,\n",
        "        target_epsilon=float(TARGET_EPSILON),\n",
        "        target_delta=TARGET_DELTA,\n",
        "        epochs=num_epochs,\n",
        "        max_grad_norm=1.0,\n",
        "    )\n",
        "\n",
        "    # Training configuration for this Îµ\n",
        "    best_test_loss = float('inf')\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    epsilons = []\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\" \"*15 + \"STARTING VERTICAL FEDERATED LEARNING\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"\\nTraining Configuration:\")\n",
        "    print(f\"  Number of epochs: {num_epochs}\")\n",
        "    print(f\"  Batch size: {train_loader.batch_size}\")\n",
        "    print(f\"  Learning rate: 0.001\")\n",
        "    print(f\"  Device: {device}\")\n",
        "    print(f\"  Target Îµ: {TARGET_EPSILON}, Î´: {TARGET_DELTA}\")\n",
        "    print(f\"\\n\" + \"=\"*70 + \"\\n\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"EPOCH {epoch+1}/{num_epochs}\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        # ---- TRAIN (DP loader) ----\n",
        "        train_loss = coordinator.train_epoch(coordinator.dp_train_loader)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # ---- TRACK EPSILON ----\n",
        "        eps = coordinator.privacy_engine.get_epsilon(delta=TARGET_DELTA)\n",
        "        epsilons.append(eps)\n",
        "        print(f\"(DP) Îµ = {eps:.2f}, Î´ = {TARGET_DELTA}\")\n",
        "\n",
        "        # ---- EVALUATE (normal test loader) ----\n",
        "        test_loss = coordinator.evaluate(test_loader)\n",
        "        test_losses.append(test_loss)\n",
        "\n",
        "        # ---- LOG ----\n",
        "        print(f\"\\n{'â”€'*70}\")\n",
        "        print(f\"Results:\")\n",
        "        print(f\"  Train Loss: {train_loss:.4f}\")\n",
        "        print(f\"  Test Loss:  {test_loss:.4f}\")\n",
        "        best_test_loss = min(best_test_loss, test_loss)\n",
        "        print(f\"{'â”€'*70}\")\n",
        "\n",
        "    all_results.append({\n",
        "        \"target_eps\": float(TARGET_EPSILON),\n",
        "        \"final_eps\": epsilons[-1],\n",
        "        \"best_test_loss\": best_test_loss,\n",
        "        \"train_losses\": train_losses,\n",
        "        \"test_losses\": test_losses,\n",
        "        \"epsilons\": epsilons,\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c33ac0db",
      "metadata": {
        "id": "c33ac0db",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Convert to numpy for easy plotting\n",
        "eps = np.array(epsilon_targets)\n",
        "train_arr = np.array(train_losses)\n",
        "test_arr = np.array(test_losses)\n",
        "\n",
        "best_test_loss = np.min(test_arr)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
        "\n",
        "# 1) Train vs Test Loss vs Target Epsilon\n",
        "ax1 = axes[0]\n",
        "ax1.plot(eps, train_arr, label='Train Loss', marker='o', linewidth=2)\n",
        "ax1.plot(eps, test_arr, label='Test Loss', marker='s', linewidth=2)\n",
        "ax1.set_xlabel(\"Target Îµ (Epsilon)\")\n",
        "ax1.set_ylabel(\"MSE Loss\")\n",
        "ax1.set_title(\"Loss vs Target Privacy Level (Îµ)\")\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# 2) Best Test Loss Marker\n",
        "ax2 = axes[1]\n",
        "ax2.scatter(eps, test_arr, c='purple', s=80)\n",
        "ax2.set_xlabel(\"Target Îµ\")\n",
        "ax2.set_ylabel(\"Test Loss\")\n",
        "ax2.set_title(\"Test Loss Across Privacy Budgets (Îµ)\")\n",
        "ax2.axhline(best_test_loss, linestyle='--', color='red',\n",
        "            label=f'Best Test Loss = {best_test_loss:.4f}')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('vfl_dp_privacy_vs_accuracy.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n===== Privacy-Utility Summary =====\")\n",
        "print(f\"Best Accuracy at Îµ = {eps[np.argmin(test_arr)]:.3f}\")\n",
        "print(f\"Best Test Loss: {best_test_loss:.4f}\")\n",
        "print(f\"Initial Test Loss: {test_arr[0]:.4f}\")\n",
        "print(f\"Improvement: {(test_arr[0] - best_test_loss):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3ec3253",
      "metadata": {
        "id": "c3ec3253",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def predict_rating(coordinator, userId, movieId):\n",
        "    \"\"\"Predict rating for a specific user-movie pair\"\"\"\n",
        "    coordinator.top_model.eval()\n",
        "    for client in coordinator.clients.values():\n",
        "        client.eval_mode()\n",
        "\n",
        "    try:\n",
        "        user_idx = user_encoder.transform([userId])[0]\n",
        "    except:\n",
        "        print(f\"Error: User {userId} not in training set\")\n",
        "        return None\n",
        "\n",
        "    # Prepare tensors\n",
        "    user_idx_tensor = torch.tensor([user_idx], dtype=torch.long).to(device)\n",
        "    movieId_tensor = torch.tensor([movieId], dtype=torch.long).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        embeddings_list = []\n",
        "        for client in coordinator.clients.values():\n",
        "            emb = client.model(movieId_tensor)\n",
        "            embeddings_list.append(emb)\n",
        "\n",
        "        combined_embeddings = torch.cat(embeddings_list, dim=1)\n",
        "        prediction = coordinator.top_model(user_idx_tensor, combined_embeddings)\n",
        "\n",
        "    return prediction.item()\n",
        "\n",
        "\n",
        "# Test on sample predictions\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" \"*20 + \"SAMPLE PREDICTIONS\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Get 5 random samples from test set\n",
        "sample_indices = np.random.choice(len(test_dataset), size=5, replace=False)\n",
        "\n",
        "for i, idx in enumerate(sample_indices, 1):\n",
        "    sample = test_dataset[idx]\n",
        "\n",
        "    userId = user_encoder.inverse_transform([sample['user_idx'].item()])[0]\n",
        "    movieId = sample['movieId'].item()\n",
        "    actual_rating = sample['rating'].item()\n",
        "\n",
        "    predicted_rating = predict_rating(coordinator, userId, movieId)\n",
        "\n",
        "    if predicted_rating is not None:\n",
        "        error = abs(actual_rating - predicted_rating)\n",
        "\n",
        "        print(f\"Prediction {i}:\")\n",
        "        print(f\"  User ID:          {userId}\")\n",
        "        print(f\"  Movie ID:         {movieId}\")\n",
        "        print(f\"  Actual Rating:    {actual_rating:.2f}\")\n",
        "        print(f\"  Predicted Rating: {predicted_rating:.2f}\")\n",
        "        print(f\"  Absolute Error:   {error:.2f}\")\n",
        "        print()\n",
        "\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Calculate overall test RMSE\n",
        "print(\"\\nCalculating overall test RMSE...\")\n",
        "all_predictions = []\n",
        "all_actuals = []\n",
        "\n",
        "coordinator.top_model.eval()\n",
        "for client in coordinator.clients.values():\n",
        "    client.eval_mode()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"Predicting\"):\n",
        "        user_idx = batch['user_idx'].to(device)\n",
        "        movieIds = batch['movieId'].to(device)\n",
        "        ratings = batch['rating'].to(device)\n",
        "\n",
        "        embeddings_list = []\n",
        "        for client in coordinator.clients.values():\n",
        "            emb = client.model(movieIds)\n",
        "            embeddings_list.append(emb)\n",
        "\n",
        "        combined_embeddings = torch.cat(embeddings_list, dim=1)\n",
        "        predictions = coordinator.top_model(user_idx, combined_embeddings)\n",
        "\n",
        "        all_predictions.extend(predictions.cpu().numpy())\n",
        "        all_actuals.extend(ratings.cpu().numpy())\n",
        "\n",
        "all_predictions = np.array(all_predictions)\n",
        "all_actuals = np.array(all_actuals)\n",
        "\n",
        "mse = np.mean((all_predictions - all_actuals) ** 2)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = np.mean(np.abs(all_predictions - all_actuals))\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\" \"*25 + \"FINAL METRICS\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"  Test MSE:  {mse:.4f}\")\n",
        "print(f\"  Test RMSE: {rmse:.4f}\")\n",
        "print(f\"  Test MAE:  {mae:.4f}\")\n",
        "print(f\"{'='*70}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0b4054b",
      "metadata": {
        "id": "c0b4054b",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "### graph neural network pytorch geometry DGL\n",
        "# 1. gat(graph attention neural network) based novel fusion mechanism -  primary client\n",
        "# 2. GNN in each client\n",
        "# 3. Differential Privacy for vertical federated learning(Opacus package)\n",
        "# 4. Image embedding with Light weight VLM with LORA\n",
        "# 5. upscale the data used\n",
        "# 6. composite key (user_id, Movie_id)\n",
        "# 7. searching for suitable reccomender system dataset(multimodal)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 115.519153,
      "end_time": "2025-12-29T10:33:38.994479",
      "environment_variables": {},
      "exception": true,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-12-29T10:31:43.475326",
      "version": "2.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}